{"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Predicting IDC in Breast Cancer Histology Images** \n* Part One: https://www.kaggle.com/paultimothymooney/predicting-idc-in-breast-cancer-histology-images/\n* * Model Selection (see link above)\n*  Part Two: Predict IDC in Breast Cancer\n* * Model Evaluation (see below)\n\nBreast cancer is the most common form of cancer in women, and invasive ductal carcinoma (IDC) is the most common form of breast cancer. Accurately identifying and categorizing breast cancer subtypes is an important clinical task, and automated methods can be used to save time and reduce error.\n\nThe goal of this script is to identify IDC when it is present in otherwise unlabeled histopathology images. The dataset consists of 277,524 50x50 pixel RGB digital image patches that were derived from 162 H&E-stained breast histopathology samples. These images are small patches that were extracted from digital images of breast tissue samples. The breast tissue contains many cells but only some of them are cancerous. Patches that are labeled \"1\" contain cells that are characteristic of invasive ductal carcinoma. For more information about the data, see https://www.ncbi.nlm.nih.gov/pubmed/27563488 and http://spie.org/Publications/Proceedings/Paper/10.1117/12.2043872.","metadata":{"_cell_guid":"570c24f2-126a-4fd3-bae2-e8247646f36d","_uuid":"118c9d31c593676aaf77c8975339e52d7cb65cdf"}},{"cell_type":"markdown","source":"*Step 1: Import Modules*","metadata":{"_cell_guid":"eb849bd9-7894-4fd3-b55d-4d0a77c9161c","_uuid":"debe60106fe79d3b2316308fd11f3d2399255c61"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport itertools\nimport fnmatch\nimport random\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport cv2\nfrom scipy.misc import imresize, imread\nimport sklearn\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport keras\nfrom keras import backend as K\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, model_from_json\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n%matplotlib inline","metadata":{"_cell_guid":"bb9fe3ef-104a-4a98-9f87-b65906acf50f","_kg_hide-input":true,"_uuid":"5a9827f8d703a8741175d1e7df3121632715bdd8","execution":{"iopub.status.busy":"2022-08-03T05:40:50.542643Z","iopub.execute_input":"2022-08-03T05:40:50.543195Z","iopub.status.idle":"2022-08-03T05:40:54.307870Z","shell.execute_reply.started":"2022-08-03T05:40:50.543115Z","shell.execute_reply":"2022-08-03T05:40:54.307088Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"*Step 2: Explore Data*","metadata":{"_cell_guid":"4c6bd2df-2a43-4604-b407-ba81c8c3939b","_uuid":"540f3c39324580297bcff94b4c4cfc0c5bb45b5f"}},{"cell_type":"code","source":"imagePatches = glob('/kaggle/input/IDC_regular_ps50_idx5/**/*.png', recursive=True)\nfor filename in imagePatches[0:10]:\n    print(filename)","metadata":{"_cell_guid":"765908c1-86cc-41df-8479-a39174231237","_uuid":"1978266e1e2fe5d6eb9bdc17deb0d309441065a2","execution":{"iopub.status.busy":"2022-08-03T05:40:54.308912Z","iopub.execute_input":"2022-08-03T05:40:54.309186Z","iopub.status.idle":"2022-08-03T05:43:45.914857Z","shell.execute_reply.started":"2022-08-03T05:40:54.309135Z","shell.execute_reply":"2022-08-03T05:43:45.912817Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"image_name = \"/kaggle/input/IDC_regular_ps50_idx5/9135/1/9135_idx5_x1701_y1851_class1.png\" #Image to be used as query\ndef plotImage(image_location):\n    image = cv2.imread(image_name)\n    image = cv2.resize(image, (50,50))\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    return\nplotImage(image_name)","metadata":{"_cell_guid":"0fd6c75a-b439-455c-ba85-24aa9d83da5b","_uuid":"1d105b2c6fff7ddfd3120215ea7f77723e360179","execution":{"iopub.status.busy":"2022-08-03T05:43:45.916004Z","iopub.execute_input":"2022-08-03T05:43:45.916278Z","iopub.status.idle":"2022-08-03T05:43:46.155447Z","shell.execute_reply.started":"2022-08-03T05:43:45.916219Z","shell.execute_reply":"2022-08-03T05:43:46.154698Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Plot Multiple Images\nbunchOfImages = imagePatches\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in bunchOfImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (50, 50)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","metadata":{"_cell_guid":"cfc417f1-c12a-42df-b264-c4e7e6e79da8","_uuid":"f9d9578ed454625dbe08a3185865cc3ae556b993","execution":{"iopub.status.busy":"2022-08-03T05:43:46.156602Z","iopub.execute_input":"2022-08-03T05:43:46.156832Z","iopub.status.idle":"2022-08-03T05:43:47.743914Z","shell.execute_reply.started":"2022-08-03T05:43:46.156790Z","shell.execute_reply":"2022-08-03T05:43:47.743071Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def randomImages(a):\n    r = random.sample(a, 4)\n    plt.figure(figsize=(16,16))\n    plt.subplot(131)\n    plt.imshow(cv2.imread(r[0]))\n    plt.subplot(132)\n    plt.imshow(cv2.imread(r[1]))\n    plt.subplot(133)\n    plt.imshow(cv2.imread(r[2])); \nrandomImages(imagePatches)","metadata":{"_cell_guid":"f010fda5-40f0-47ce-89c0-40d21a754f59","_uuid":"10cc771383f08fd404419bccaa00ed9ad99cd0e2","execution":{"iopub.status.busy":"2022-08-03T05:43:47.745132Z","iopub.execute_input":"2022-08-03T05:43:47.745348Z","iopub.status.idle":"2022-08-03T05:43:48.120208Z","shell.execute_reply.started":"2022-08-03T05:43:47.745313Z","shell.execute_reply":"2022-08-03T05:43:48.119494Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"*Step 3: Preprocess Data*","metadata":{"_cell_guid":"5f695df0-da48-4cc5-93a0-dcb7a82d21a3","_uuid":"c88fc872e6af3918192df09635e88904145761a2"}},{"cell_type":"code","source":"patternZero = '*class0.png'\npatternOne = '*class1.png'\nclassZero = fnmatch.filter(imagePatches, patternZero)\nclassOne = fnmatch.filter(imagePatches, patternOne)\nprint(\"IDC(-)\\n\\n\",classZero[0:5],'\\n')\nprint(\"IDC(+)\\n\\n\",classOne[0:5])","metadata":{"_cell_guid":"939bc134-6122-4d4d-aa6c-89a47318896d","_uuid":"aae6a2ec2ab20bd94422e29b147a45a880fb480a","execution":{"iopub.status.busy":"2022-08-03T05:43:48.121342Z","iopub.execute_input":"2022-08-03T05:43:48.121644Z","iopub.status.idle":"2022-08-03T05:43:48.426567Z","shell.execute_reply.started":"2022-08-03T05:43:48.121592Z","shell.execute_reply":"2022-08-03T05:43:48.425768Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def proc_images(lowerIndex,upperIndex):\n    \"\"\"\n    Returns two arrays: \n        x is an array of resized images\n        y is an array of labels\n    \"\"\" \n    x = []\n    y = []\n    WIDTH = 50\n    HEIGHT = 50\n    for img in imagePatches[lowerIndex:upperIndex]:\n        full_size_image = cv2.imread(img)\n        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n        if img in classZero:\n            y.append(0)\n        elif img in classOne:\n            y.append(1)\n        else:\n            return\n    return x,y","metadata":{"_cell_guid":"f62e9e56-6564-4376-845f-284f624fa932","_uuid":"69640054f59133ebe8dfa06612f3c14383916e90","execution":{"iopub.status.busy":"2022-08-03T05:43:48.427949Z","iopub.execute_input":"2022-08-03T05:43:48.428414Z","iopub.status.idle":"2022-08-03T05:43:48.445594Z","shell.execute_reply.started":"2022-08-03T05:43:48.428235Z","shell.execute_reply":"2022-08-03T05:43:48.444724Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X,Y = proc_images(0,90000)\ndf = pd.DataFrame()\ndf[\"images\"]=X\ndf[\"labels\"]=Y\nX2=df[\"images\"]\nY2=df[\"labels\"]\nX2=np.array(X2)\nimgs0=[]\nimgs1=[]\nimgs0 = X2[Y2==0] # (0 = no IDC, 1 = IDC)\nimgs1 = X2[Y2==1] ","metadata":{"_cell_guid":"3bf67ef8-5613-4862-bc46-0106d1880981","_uuid":"2b8fd5414423f1e7ff7da620d8672bb496a9ef57","execution":{"iopub.status.busy":"2022-08-03T05:43:48.446942Z","iopub.execute_input":"2022-08-03T05:43:48.447458Z","iopub.status.idle":"2022-08-03T05:54:36.312226Z","shell.execute_reply.started":"2022-08-03T05:43:48.447378Z","shell.execute_reply":"2022-08-03T05:54:36.311545Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def describeData(a,b):\n    print('Total number of images: {}'.format(len(a)))\n    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))\n    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))\n    print('Percentage of positive images: {:.2f}%'.format(100*np.mean(b)))\n    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\ndescribeData(X2,Y2)","metadata":{"_cell_guid":"b3c1681f-7576-4b3d-ad49-7832e3bcf209","_uuid":"5660e633007abaeda0a4698b8bfacf55d9552ab4","execution":{"iopub.status.busy":"2022-08-03T05:54:36.313290Z","iopub.execute_input":"2022-08-03T05:54:36.313533Z","iopub.status.idle":"2022-08-03T05:54:36.327989Z","shell.execute_reply.started":"2022-08-03T05:54:36.313490Z","shell.execute_reply":"2022-08-03T05:54:36.327169Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dict_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\nprint(df.head(10))\nprint(\"\")\nprint(dict_characters)","metadata":{"_cell_guid":"0c3b967b-674c-4efa-b59e-56772166ef41","_uuid":"9eed051f46211121a7add96c9cf86165340a7e28","execution":{"iopub.status.busy":"2022-08-03T05:54:36.329300Z","iopub.execute_input":"2022-08-03T05:54:36.330013Z","iopub.status.idle":"2022-08-03T05:54:39.269422Z","shell.execute_reply.started":"2022-08-03T05:54:36.329938Z","shell.execute_reply":"2022-08-03T05:54:39.268665Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def plotOne(a,b):\n    \"\"\"\n    Plot one numpy array\n    \"\"\"\n    plt.subplot(1,2,1)\n    plt.title('IDC (-)')\n    plt.imshow(a[0])\n    plt.subplot(1,2,2)\n    plt.title('IDC (+)')\n    plt.imshow(b[0])\nplotOne(imgs0, imgs1) ","metadata":{"_cell_guid":"d72d8a7d-7234-4a68-92f9-8f3578e08e36","_uuid":"3836924a638d95d90d85a02829bd85933f3c495f","execution":{"iopub.status.busy":"2022-08-03T05:54:39.270566Z","iopub.execute_input":"2022-08-03T05:54:39.270805Z","iopub.status.idle":"2022-08-03T05:54:39.502739Z","shell.execute_reply.started":"2022-08-03T05:54:39.270764Z","shell.execute_reply":"2022-08-03T05:54:39.501941Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def plotTwo(a,b): \n    \"\"\"\n    Plot a bunch of numpy arrays sorted by label\n    \"\"\"\n    for row in range(3):\n        plt.figure(figsize=(20, 10))\n        for col in range(3):\n            plt.subplot(1,8,col+1)\n            plt.title('IDC (-)')\n            plt.imshow(a[0+row+col])\n            plt.axis('off')       \n            plt.subplot(1,8,col+4)\n            plt.title('IDC (+)')\n            plt.imshow(b[0+row+col])\n            plt.axis('off')\nplotTwo(imgs0, imgs1) ","metadata":{"_cell_guid":"389ea274-9f97-45e6-a99f-d3362412e721","_uuid":"c83c02425f516da672e7957f0cd42ecc72dce981","execution":{"iopub.status.busy":"2022-08-03T05:54:39.503891Z","iopub.execute_input":"2022-08-03T05:54:39.504123Z","iopub.status.idle":"2022-08-03T05:54:40.728683Z","shell.execute_reply.started":"2022-08-03T05:54:39.504081Z","shell.execute_reply":"2022-08-03T05:54:40.727836Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"The data is scaled from 0 to 256 but we want it to be scaled from 0 to 1. This will make the data compatible with a wide variety of different classification algorithms.  We also want to set aside 20% of the data for testing. This will make the trained model less prone to overfitting.  And finally, we will use an oversampling strategy to deal with the imbalanced class sizes.","metadata":{"_cell_guid":"254e9903-c303-46cd-bde9-0d3b412e6cdb","_uuid":"4d584d18cb934f1cf025e9bbb6d6cb8c03542494"}},{"cell_type":"code","source":"def plotHistogram(a):\n    \"\"\"\n    Plot histogram of RGB Pixel Intensities\n    \"\"\"\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    plt.imshow(a)\n    plt.axis('off')\n    plt.title('IDC(+)' if Y[1] else 'IDC(-)')\n    histo = plt.subplot(1,2,2)\n    histo.set_ylabel('Count')\n    histo.set_xlabel('Pixel Intensity')\n    n_bins = 30\n    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\nplotHistogram(X2[100])","metadata":{"_cell_guid":"c5d01476-b570-4fb4-8ebb-1af69f3e215e","_uuid":"23ca1626461e4749493064070986a075f8317539","execution":{"iopub.status.busy":"2022-08-03T05:54:40.729943Z","iopub.execute_input":"2022-08-03T05:54:40.730427Z","iopub.status.idle":"2022-08-03T05:54:41.239760Z","shell.execute_reply.started":"2022-08-03T05:54:40.730355Z","shell.execute_reply":"2022-08-03T05:54:41.239188Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X=np.array(X)\nX=X/255.0\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n\n# Reduce Sample Size for DeBugging\nX_train = X_train[0:300000] \nY_train = Y_train[0:300000]\nX_test = X_test[0:300000] \nY_test = Y_test[0:300000]\n\nprint(\"Training Data Shape:\", X_train.shape)\nprint(\"Testing Data Shape:\", X_test.shape)","metadata":{"_cell_guid":"9f9e4c80-a8e0-47ac-957b-22231b1e9fca","_uuid":"ae82d3f7ec59d7d112a8dd9ed1b8121a4792a1b0","execution":{"iopub.status.busy":"2022-08-03T05:54:41.240679Z","iopub.execute_input":"2022-08-03T05:54:41.241017Z","iopub.status.idle":"2022-08-03T05:55:02.243018Z","shell.execute_reply.started":"2022-08-03T05:54:41.240979Z","shell.execute_reply":"2022-08-03T05:55:02.241845Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"plotHistogram(X_train[100])","metadata":{"_cell_guid":"b07de5e9-53dd-49e5-9da3-778bc9eb9b17","_uuid":"5d808c28fb0f9aaa0364d8b62d11fc1f2810c2c8","execution":{"iopub.status.busy":"2022-08-03T05:55:02.245176Z","iopub.execute_input":"2022-08-03T05:55:02.245788Z","iopub.status.idle":"2022-08-03T05:55:02.611421Z","shell.execute_reply.started":"2022-08-03T05:55:02.245719Z","shell.execute_reply":"2022-08-03T05:55:02.610596Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_trainHot = to_categorical(Y_train, num_classes = 2)\nY_testHot = to_categorical(Y_test, num_classes = 2)","metadata":{"_cell_guid":"a23e5463-5d12-43c8-8a3a-eb7dcfecdf6b","_uuid":"447f1371f137cf51962a0f32171d44a3080a694c","execution":{"iopub.status.busy":"2022-08-03T05:55:02.612619Z","iopub.execute_input":"2022-08-03T05:55:02.612996Z","iopub.status.idle":"2022-08-03T05:55:02.626458Z","shell.execute_reply.started":"2022-08-03T05:55:02.612954Z","shell.execute_reply":"2022-08-03T05:55:02.625615Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"lab = df['labels']\ndist = lab.value_counts()\nsns.countplot(lab)\nprint(dict_characters)","metadata":{"_cell_guid":"ab055bcf-2a2c-4645-b043-45d28ddcc782","_uuid":"1c05f8d5a5ada31b3741944ac02d480c2b39619f","execution":{"iopub.status.busy":"2022-08-03T05:55:02.627640Z","iopub.execute_input":"2022-08-03T05:55:02.628057Z","iopub.status.idle":"2022-08-03T05:55:02.800707Z","shell.execute_reply.started":"2022-08-03T05:55:02.628015Z","shell.execute_reply":"2022-08-03T05:55:02.800112Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Deal with imbalanced class sizes below\n# Make Data 1D for compatability upsampling methods\nX_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\nX_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\nX_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\nX_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\n#print(\"X_train Shape: \",X_train.shape)\n#print(\"X_test Shape: \",X_test.shape)\n#print(\"X_trainFlat Shape: \",X_trainFlat.shape)\n#print(\"X_testFlat Shape: \",X_testFlat.shape)\n\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n#ros = RandomOverSampler(ratio='auto')\nros = RandomUnderSampler(ratio='auto')\nX_trainRos, Y_trainRos = ros.fit_sample(X_trainFlat, Y_train)\nX_testRos, Y_testRos = ros.fit_sample(X_testFlat, Y_test)\n\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_trainRosHot = to_categorical(Y_trainRos, num_classes = 2)\nY_testRosHot = to_categorical(Y_testRos, num_classes = 2)\n#print(\"X_train: \", X_train.shape)\n#print(\"X_trainFlat: \", X_trainFlat.shape)\n#print(\"X_trainRos Shape: \",X_trainRos.shape)\n#print(\"X_testRos Shape: \",X_testRos.shape)\n#print(\"Y_trainRosHot Shape: \",Y_trainRosHot.shape)\n#print(\"Y_testRosHot Shape: \",Y_testRosHot.shape)\n\nfor i in range(len(X_trainRos)):\n    height, width, channels = 50,50,3\n    X_trainRosReshaped = X_trainRos.reshape(len(X_trainRos),height,width,channels)\n#print(\"X_trainRos Shape: \",X_trainRos.shape)\n#print(\"X_trainRosReshaped Shape: \",X_trainRosReshaped.shape)\n\nfor i in range(len(X_testRos)):\n    height, width, channels = 50,50,3\n    X_testRosReshaped = X_testRos.reshape(len(X_testRos),height,width,channels)\n#print(\"X_testRos Shape: \",X_testRos.shape)\n#print(\"X_testRosReshaped Shape: \",X_testRosReshaped.shape)\n\ndfRos = pd.DataFrame()\ndfRos[\"labels\"]=Y_trainRos\nlabRos = dfRos['labels']\ndistRos = lab.value_counts()\nsns.countplot(labRos)\nprint(dict_characters)","metadata":{"_cell_guid":"06cb3ea4-371a-4971-9449-dc726f06e16b","_uuid":"5d3087f0dfe874a591449b9d5f27da138f42f0c6","execution":{"iopub.status.busy":"2022-08-03T05:55:02.801686Z","iopub.execute_input":"2022-08-03T05:55:02.802028Z","iopub.status.idle":"2022-08-03T05:55:09.227829Z","shell.execute_reply.started":"2022-08-03T05:55:02.801988Z","shell.execute_reply":"2022-08-03T05:55:09.226864Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"*Step 4: Define Helper Functions for the Classification Task*","metadata":{"_cell_guid":"11ec5cdf-44ad-4bf6-8975-4fa4682d5e2a","_uuid":"9265cdcdeb26c3169db18392ce1603885129a130"}},{"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weight = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\nprint(\"Old Class Weights: \",class_weight)\nfrom sklearn.utils import class_weight\nclass_weight2 = class_weight.compute_class_weight('balanced', np.unique(Y_trainRos), Y_trainRos)\nprint(\"New Class Weights: \",class_weight2)","metadata":{"_cell_guid":"5a0e446b-a55a-4933-b4a7-198da1669545","_uuid":"ec338837016d3d5222e98a10331b1b2de457db34","execution":{"iopub.status.busy":"2022-08-03T05:55:09.229022Z","iopub.execute_input":"2022-08-03T05:55:09.229265Z","iopub.status.idle":"2022-08-03T05:55:09.271145Z","shell.execute_reply.started":"2022-08-03T05:55:09.229218Z","shell.execute_reply":"2022-08-03T05:55:09.270521Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Helper Functions  Learning Curves and Confusion Matrix\n\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./accuracy_curve.png')\n    #plt.clf()\n    # summarize history for loss\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./loss_curve.png')","metadata":{"_cell_guid":"137bc037-a8a4-4dac-aecd-62d6efc6c127","_uuid":"4a883a6aaddd3261a630af0f12ed7e542da3eb3f","execution":{"iopub.status.busy":"2022-08-03T05:55:09.272147Z","iopub.execute_input":"2022-08-03T05:55:09.272530Z","iopub.status.idle":"2022-08-03T05:55:09.552709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Step 5: Evaluate Classification Models*","metadata":{"_cell_guid":"0fe72b01-0848-4ac9-b4b8-a2d212cfcc2d","_uuid":"4524ae34f83914f75a2da05afba664cf7f0ea505"}},{"cell_type":"markdown","source":"In a previous kernel I evaluated a number of different classification algorithms while using an abbreviated form of this same dataset.  To see how and why I chose the model that I use below, please see the following link: https://www.kaggle.com/paultimothymooney/predicting-idc-in-breast-cancer-histology-images/","metadata":{"_cell_guid":"fde814f1-38f0-402f-81da-c7f899791b4b","_uuid":"5fb738a2cb7f08a57ca493c948a44d9df975d3d7"}},{"cell_type":"code","source":"def runKerasCNNAugment(a,b,c,d,e,f):\n    \"\"\"\n    Run Keras CNN: https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n    \"\"\"\n    batch_size = 128\n    num_classes = 2\n    epochs = 8\n#     img_rows, img_cols = a.shape[1],a.shape[2]\n    img_rows,img_cols=50,50\n    input_shape = (img_rows, img_cols, 3)\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                     activation='relu',\n                     input_shape=input_shape,strides=e))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=keras.optimizers.Adadelta(),\n                  metrics=['accuracy'])\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n    history = model.fit_generator(datagen.flow(a,b, batch_size=32),\n                        steps_per_epoch=len(a) / 32, epochs=epochs,class_weight=f, validation_data = [c, d],callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(c,d, verbose=0)\n    print('\\nKeras CNN #1C - accuracy:', score[1],'\\n')\n    y_pred = model.predict(c)\n    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')    \n    Y_pred_classes = np.argmax(y_pred,axis=1) \n    Y_true = np.argmax(d,axis=1) \n    plotKerasLearningCurve()\n    plt.show()  \n    plot_learning_curve(history)\n    plt.show()\n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx, classes = list(dict_characters.values())) \n    plt.show()\nrunKerasCNNAugment(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,2,class_weight2)","metadata":{"_cell_guid":"47acf66e-5542-4f73-908c-11f76ed8becf","_uuid":"6d7e57d88e5578aea8b0b8f397d2a689e9c74de0","execution":{"iopub.status.busy":"2022-08-03T05:55:09.554464Z","iopub.execute_input":"2022-08-03T05:55:09.555056Z","iopub.status.idle":"2022-08-03T06:11:44.413356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next I will try one more time but without the undersampling step.","metadata":{"_cell_guid":"a03f19fc-05c4-4f8a-8e0b-a921c781ff10","_uuid":"7bc3bc872c444fe5990aa365a832b6dc9c9bdad8"}},{"cell_type":"code","source":"#runKerasCNNAugment(X_train, Y_trainHot, X_test, Y_testHot,2,class_weight)","metadata":{"_cell_guid":"97db66e5-0fc8-4e1d-bfc0-179c3391f08f","_uuid":"9854e5bb4554a4bea7d59a37ec6d4a24ce141fc0","execution":{"iopub.status.busy":"2022-08-03T06:11:44.414530Z","iopub.execute_input":"2022-08-03T06:11:44.414781Z","iopub.status.idle":"2022-08-03T06:11:44.419092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"90+% accuracy is pretty good!  And it does not look too be to overfit or too biased based off of the learning curve and confusion matrix.  In the future, I will improve the score by optimizing the data augmentation step as well as the network architecture.","metadata":{"_cell_guid":"3e4418ff-dabc-46b4-8fa9-7daaab1402a7","_uuid":"069b85a95cbc0c4aa7e71b64ad9ef3c8aebf4373"}}]}